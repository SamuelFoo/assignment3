{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from natsort import natsorted\n",
    "import cv2\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YOLOToCOCOBox(box, imgXY):\n",
    "    '''Convert from normalised xc,yc,w,h to x1,y1,w,h'''\n",
    "    xc,yc,w,h = box\n",
    "    imgX, imgY = imgXY\n",
    "    return [(xc-w/2)*imgX, (yc-h/2)*imgY, w*imgX, h*imgY]\n",
    "\n",
    "def helper(frameCount, framesWithLabels, labelPaths, frame, displayFlag):\n",
    "    if frameCount in framesWithLabels:\n",
    "        idx = framesWithLabels.index(frameCount)\n",
    "        labelPath = labelPaths[idx]\n",
    "        shutil.copy2(labelPath, labelRootDir/labelPath.name)\n",
    "        cv2.imwrite(str(imgRootDir/f\"{labelPath.stem}.jpg\"), frame)\n",
    "\n",
    "        if displayFlag:\n",
    "            f = open(labelPath, \"r\")\n",
    "            fileContents = f.read()\n",
    "            boxes = [] if fileContents == \"\" else fileContents.strip().split(\"\\n\")\n",
    "            boxes = [[float(num) for num in box.strip().split()[1:]] for box in boxes]\n",
    "            \n",
    "            for box in boxes:\n",
    "                x, y, w, h = YOLOToCOCOBox(box, frame.shape[-2::-1])\n",
    "                cv2.rectangle(frame, (int(x), int(y)), (int(x + w), int(y + h)), (0,0,255), 3)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirPath = Path(f\"track\")\n",
    "labelPaths = list(dirPath.glob(\"*.txt\"))\n",
    "framesWithLabels = [int(path.stem.strip(\"frame_\")) for path in labelPaths]\n",
    "\n",
    "saveDir = Path(f\"detect\")\n",
    "imgRootDir = saveDir/\"images\"/\"root\"\n",
    "labelRootDir = saveDir/\"labels\"/\"root\"\n",
    "imgRootDir.mkdir(parents=True, exist_ok=True)\n",
    "labelRootDir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DISPLAY_FLAG = False\n",
    "\n",
    "vidPath = dirPath/\"video.mp4\"\n",
    "\n",
    "frameCount = 0\n",
    "cap = cv2.VideoCapture(str(vidPath))\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    if frameCount in framesWithLabels:\n",
    "        frame = helper(frameCount, framesWithLabels, labelPaths, frame, DISPLAY_FLAG)\n",
    "\n",
    "    if DISPLAY_FLAG:\n",
    "        frame = imutils.resize(frame, height=500)\n",
    "        cv2.imshow(\"Ground Truth\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord(\"q\") or key == ord(\"Q\"):\n",
    "            break\n",
    "\n",
    "    frameCount += 1\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirPath = Path(f\"detect\")\n",
    "imgPaths = natsorted(dirPath.glob(\"images/root/*\"))\n",
    "\n",
    "assert len(imgPaths) == len(list(dirPath.glob(\"labels/root/*\")))\n",
    "\n",
    "for imgPath in imgPaths:\n",
    "    img = cv2.imread(str(imgPath))\n",
    "    labelPath = str(imgPath).replace(\"images\", \"labels\").replace(\".jpg\", \".txt\").replace(\".png\", \".txt\")\n",
    "    \n",
    "    f = open(labelPath, \"r\")\n",
    "    fileContents = f.read()\n",
    "    boxes = [] if fileContents == \"\" else fileContents.strip().split(\"\\n\")\n",
    "    boxes = [[float(num) for num in box.strip().split()[1:]] for box in boxes]\n",
    "    \n",
    "    for box in boxes:\n",
    "        x, y, w, h = YOLOToCOCOBox(box, img.shape[-2::-1])\n",
    "        cv2.rectangle(img, (int(x), int(y)), (int(x + w), int(y + h)), (0,0,255), 3)\n",
    "\n",
    "    img = imutils.resize(img, height=500)\n",
    "    cv2.imshow(\"Ground Truth\", img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\") or key == ord(\"Q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Training, Validation, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabelPaths(imagePaths):\n",
    "    labelPaths = np.char.replace(imagePaths.astype(str), \"images\", \"labels\")\n",
    "    labelPaths = np.char.replace(labelPaths.astype(str), \"jpg\", \"txt\")\n",
    "    labelPaths = np.char.replace(labelPaths.astype(str), \"png\", \"txt\")\n",
    "    return labelPaths\n",
    "\n",
    "def copyFiles(currPaths, datasetType):\n",
    "    saveDir = Path(currPaths[0].replace(\"root\", datasetType)).parent\n",
    "    saveDir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for src in currPaths:\n",
    "        dst = src.replace(\"root\", datasetType)\n",
    "        shutil.copy2(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validProp = 0.2\n",
    "testProp = 0.01\n",
    "\n",
    "rootDir = Path(f\"detect/images/root\")\n",
    "\n",
    "imagePaths = np.array(natsorted(rootDir.glob(\"*\")))\n",
    "np.random.seed(314159)\n",
    "validAndTest = np.random.choice(imagePaths, int(len(imagePaths)*(validProp+testProp)), replace=False)\n",
    "valid = np.random.choice(validAndTest, int(len(imagePaths)*validProp), replace=False)\n",
    "test = validAndTest[~np.isin(validAndTest, valid)]\n",
    "train = imagePaths[~np.isin(imagePaths, validAndTest)]\n",
    "\n",
    "trainLabels = getLabelPaths(train)\n",
    "validLabels = getLabelPaths(valid)\n",
    "testLabels = getLabelPaths(test)\n",
    "\n",
    "trainDir = Path(f\"detect/images/train\")\n",
    "validDir = Path(f\"detect/images/valid\")\n",
    "testDir = Path(f\"detect/images/test\")\n",
    "shutil.rmtree(trainDir, ignore_errors=True)\n",
    "shutil.rmtree(validDir, ignore_errors=True)\n",
    "shutil.rmtree(testDir, ignore_errors=True)\n",
    "\n",
    "copyFiles(trainLabels, \"train\")\n",
    "copyFiles(validLabels, \"valid\")\n",
    "copyFiles(testLabels, \"test\")\n",
    "copyFiles(train.astype(str), \"train\")\n",
    "copyFiles(valid.astype(str), \"valid\")\n",
    "copyFiles(test.astype(str), \"test\")\n",
    "\n",
    "\n",
    "print(\"Total:\")\n",
    "print(f\"\"\"\\\n",
    "    Test Size: {len(test)}\n",
    "    Validation Size: {len(valid)}\n",
    "    Training Size: {len(train)}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import imutils\n",
    "\n",
    "modelName = \"yolov8n_010923_1\"\n",
    "\n",
    "model = YOLO(f'weights/{modelName}.pt')\n",
    "model.export(format='onnx', opset=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants.\n",
    "INPUT_WIDTH = 640\n",
    "INPUT_HEIGHT = 640\n",
    "SCORE_THRESHOLD = 0.5\n",
    "NMS_THRESHOLD = 0.45\n",
    "CONFIDENCE_THRESHOLD = 0.45\n",
    " \n",
    "# Text parameters.\n",
    "FONT_FACE = cv2.FONT_HERSHEY_SIMPLEX\n",
    "FONT_SCALE = 0.7\n",
    "THICKNESS = 1\n",
    " \n",
    "# Colors.\n",
    "BLACK  = (0,0,0)\n",
    "BLUE   = (255,178,50)\n",
    "YELLOW = (0,255,255)\n",
    "\n",
    "classes = [\"red\", \"green\", \"black\", \"turntable\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_label(im, label, x, y):\n",
    "    \"\"\"Draw text onto image at location.\"\"\"\n",
    "    # Get text size.\n",
    "    text_size = cv2.getTextSize(label, FONT_FACE, FONT_SCALE, THICKNESS)\n",
    "    dim, baseline = text_size[0], text_size[1]\n",
    "    # Use text size to create a BLACK rectangle.\n",
    "    cv2.rectangle(im, (x,y), (x + dim[0], y + dim[1] + baseline), (0,0,0), cv2.FILLED)\n",
    "    # Display text inside the rectangle.\n",
    "    cv2.putText(im, label, (x, y + dim[1]), FONT_FACE, FONT_SCALE, YELLOW, THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "def pre_process(input_image, net):\n",
    "    # Create a 4D blob from a frame.\n",
    "    blob = cv2.dnn.blobFromImage(input_image, 1/255, (INPUT_WIDTH, INPUT_HEIGHT), [0,0,0], 1, crop=False)\n",
    "\n",
    "    # Sets the input to the network.\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Run the forward pass to get output of the output layers.\n",
    "    outputs = net.forward(net.getUnconnectedOutLayersNames())\n",
    "    return outputs\n",
    "\n",
    "def post_process(input_image, outputs):\n",
    "    # Lists to hold respective values while unwrapping.\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    rowsTest = []\n",
    "    # Rows.\n",
    "    detections = outputs[0][0].T\n",
    "    rows = len(detections)\n",
    "    image_height, image_width = input_image.shape[:2]\n",
    "    # Resizing factor.\n",
    "    x_factor = image_width / INPUT_WIDTH\n",
    "    y_factor =  image_height / INPUT_HEIGHT\n",
    "    # print(x_factor, y_factor)\n",
    "    # Iterate through detections.\n",
    "    for r in range(rows):\n",
    "        row = detections[r]\n",
    "        # Discard bad detections and continue.\n",
    "        # if confidence >= CONFIDENCE_THRESHOLD:\n",
    "        if True:\n",
    "            classes_scores = row[4:]\n",
    "            # Get the index of max class score.\n",
    "            # print(len(classes_scores))\n",
    "            class_id = np.argmax(classes_scores)\n",
    "            # print(class_id)\n",
    "            #  Continue if the class score is above threshold.\n",
    "            if (classes_scores[class_id] > SCORE_THRESHOLD):\n",
    "                class_ids.append(class_id)\n",
    "                labels.append(\"{}\".format(classes[class_id]))\n",
    "                # rowsTest.append(row)\n",
    "                cx, cy, w, h = row[0], row[1], row[2], row[3]\n",
    "                left = int((cx - w/2) * x_factor)\n",
    "                top = int((cy - h/2) * y_factor)\n",
    "                width = int(w * x_factor)\n",
    "                height = int(h * y_factor)\n",
    "                box = np.array([left, top, width, height])\n",
    "                boxes.append(box)\n",
    "                \n",
    "    # Perform non maximum suppression to eliminate redundant, overlapping boxes with lower confidences.\n",
    "    # print(len(boxes))\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, np.repeat(1.0, len(boxes)), CONFIDENCE_THRESHOLD, NMS_THRESHOLD)\n",
    "    for i in indices:\n",
    "        box = boxes[i]\n",
    "        # row = rowsTest[i]\n",
    "        left = box[0]\n",
    "        top = box[1]\n",
    "        width = box[2]\n",
    "        height = box[3]             \n",
    "        # Draw bounding box.\n",
    "        # print(box)\n",
    "        # print(row) \n",
    "        cv2.rectangle(input_image, (left, top), (left + width, top + height), BLUE, 3*THICKNESS)\n",
    "        # Class label.           \n",
    "        # Draw label.             \n",
    "        draw_label(input_image, labels[i], left, top)\n",
    "    return boxes, labels, input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromONNX(\"weights/yolov8n_010923_1.onnx\")\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "cap = cv2.VideoCapture(\"track/video.mp4\")\n",
    "\n",
    "ret, frame = cap.read()\n",
    "while ret:\n",
    "    outputs = pre_process(frame, net)\n",
    "    boxes, labels, im = post_process(frame, outputs)\n",
    "    t, _ = net.getPerfProfile()\n",
    "    label = 'Inference time: %.2f ms' % (t * 1000.0 /  cv2.getTickFrequency())\n",
    "    # print(label)\n",
    "    cv2.putText(im, label, (20, 40), FONT_FACE, FONT_SCALE,  (0, 0, 255), THICKNESS, cv2.LINE_AA)\n",
    "    cv2.imshow('Output', imutils.resize(im, width=1000))\n",
    "    # cv2.namedWindow(\"Output\", cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_AUTOSIZE)\n",
    "    # cv2.imshow('Output', im)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
